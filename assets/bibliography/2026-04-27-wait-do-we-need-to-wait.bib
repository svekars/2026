@misc{zhang2025surveytesttimescalinglarge,
	title        = {A Survey on Test-Time Scaling in Large Language Models: What, How, Where, and How Well?},
	author       = {Qiyuan Zhang and Fuyuan Lyu and Zexu Sun and Lei Wang and Weixu Zhang and Wenyue Hua and Haolun Wu and Zhihan Guo and Yufei Wang and Niklas Muennighoff and Irwin King and Xue Liu and Chen Ma},
	year         = 2025,
	url          = {https://arxiv.org/abs/2503.24235},
	eprint       = {2503.24235},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{muennighoff-etal-2025-s1,
	title        = {s1: Simple test-time scaling},
	author       = {Muennighoff, Niklas  and Yang, Zitong  and Shi, Weijia  and Li, Xiang Lisa  and Fei-Fei, Li  and Hajishirzi, Hannaneh  and Zettlemoyer, Luke  and Liang, Percy  and Candes, Emmanuel  and Hashimoto, Tatsunori},
	year         = 2025,
	month        = nov,
	booktitle    = {Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
	publisher    = {Association for Computational Linguistics},
	address      = {Suzhou, China},
	pages        = {20286--20332},
	doi          = {10.18653/v1/2025.emnlp-main.1025},
	isbn         = {979-8-89176-332-6},
	url          = {https://aclanthology.org/2025.emnlp-main.1025/},
	editor       = {Christodoulopoulos, Christos  and Chakraborty, Tanmoy  and Rose, Carolyn  and Peng, Violet},
	abstract     = {Test-time scaling is a promising new approach to language modeling that uses extra test-time compute to improve performance. Recently, OpenAI{'}s o1 model showed this capability but did not publicly share its methodology, leading to many replication efforts. We seek the simplest approach to achieve test-time scaling and strong reasoning performance. First, we curate a small dataset s1K of 1,000 questions paired with reasoning traces relying on three criteria we validate through ablations: difficulty, diversity, and quality. Second, we develop budget forcing to control test-time compute by forcefully terminating the model{'}s thinking process or lengthening it by appending ``Wait'' multiple times to the model{'}s generation when it tries to end. This can lead the model to double-check its answer, often fixing incorrect reasoning steps. After supervised finetuning the Qwen2.5-32B-Instruct language model on s1K and equipping it with budget forcing, our model s1 exceeds o1-preview on competition math questions by up to 27{\%} (MATH and AIME24). Further, scaling s1 with budget forcing allows extrapolating beyond its performance without test-time intervention: from 50{\%} to 57{\%} on AIME24. Our model, data, and code are open-source at https://github.com/simplescaling/s1.}
}
@misc{ringel2025learningcontinuethinkingtokenenhanced,
	title        = {Learning a Continue-Thinking Token for Enhanced Test-Time Scaling},
	author       = {Liran Ringel and Elad Tolochinsky and Yaniv Romano},
	year         = 2025,
	url          = {https://arxiv.org/abs/2506.11274},
	eprint       = {2506.11274},
	archiveprefix = {arXiv},
	primaryclass = {cs.CL}
}
@inproceedings{jurayj-etal-2025-final,
	title        = {Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering},
	author       = {Jurayj, William  and Cheng, Jeffrey  and Van Durme, Benjamin},
	year         = 2025,
	month        = jul,
	booktitle    = {Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
	publisher    = {Association for Computational Linguistics},
	address      = {Vienna, Austria},
	pages        = {636--644},
	doi          = {10.18653/v1/2025.acl-short.50},
	isbn         = {979-8-89176-252-7},
	url          = {https://aclanthology.org/2025.acl-short.50/},
	editor       = {Che, Wanxiang  and Nabende, Joyce  and Shutova, Ekaterina  and Pilehvar, Mohammad Taher},
	abstract     = {Scaling the test-time compute of large language models has demonstrated impressive performance on reasoning benchmarks. However, existing evaluations of test-time scaling make the strong assumption that a reasoning system should always give an answer to any question provided. This overlooks concerns about whether a model is confident in its answer, and whether it is appropriate to always provide a response. To address these concerns, we extract confidence scores during reasoning for thresholding model responses. We find that increasing compute budget at inference time not only helps models answer more questions correctly, but also increases confidence in correct responses. We then extend the current paradigm of zero-risk responses during evaluation by considering settings with non-zero levels of response risk, and suggest a recipe for reporting evaluations under these settings.}
}
@inproceedings{gandhi2025cognitive,
	title        = {Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective {ST}aRs},
	author       = {Kanishk Gandhi and Ayush K Chakravarthy and Anikait Singh and Nathan Lile and Noah Goodman},
	year         = 2025,
	booktitle    = {Second Conference on Language Modeling},
	url          = {https://openreview.net/forum?id=QGJ9ttXLTy}
}
@misc{feng2025characterizeseffectivereasoningrevisiting,
	title        = {What Characterizes Effective Reasoning? Revisiting Length, Review, and Structure of CoT},
	author       = {Yunzhen Feng and Julia Kempe and Cheng Zhang and Parag Jain and Anthony Hartshorn},
	year         = 2025,
	url          = {https://arxiv.org/abs/2509.19284},
	eprint       = {2509.19284},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{wu2025itssimpleanalysissimple,
	title        = {It's Not That Simple. An Analysis of Simple Test-Time Scaling},
	author       = {Guojun Wu},
	year         = 2025,
	url          = {https://arxiv.org/abs/2507.14419},
	eprint       = {2507.14419},
	archiveprefix = {arXiv},
	primaryclass = {cs.LG}
}
@misc{zhao2025testtimescalingreasoningmodels,
	title        = {Test-Time Scaling in Reasoning Models Is Not Effective for Knowledge-Intensive Tasks Yet},
	author       = {James Xu Zhao and Bryan Hooi and See-Kiong Ng},
	year         = 2025,
	url          = {https://arxiv.org/abs/2509.06861},
	eprint       = {2509.06861},
	archiveprefix = {arXiv},
	primaryclass = {cs.AI}
}
@inproceedings{huang2025m,
	title        = {m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning in Large Language Models},
	author       = {Xiaoke Huang and Juncheng Wu and Hui Liu and Xianfeng Tang and Yuyin Zhou},
	year         = 2025,
	booktitle    = {The Second Workshop on GenAI for Health: Potential, Trust, and Policy Compliance},
	url          = {https://openreview.net/forum?id=9l6unbTnQi}
}
@inproceedings{wang2025beyond,
	title        = {Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for {LLM} Reasoning},
	author       = {Shenzhi Wang and Le Yu and Chang Gao and Chujie Zheng and Shixuan Liu and Rui Lu and Kai Dang and Xiong-Hui Chen and Jianxin Yang and Zhenru Zhang and Yuqiong Liu and An Yang and Andrew Zhao and Yang Yue and Shiji Song and Bowen Yu and Gao Huang and Junyang Lin},
	year         = 2025,
	booktitle    = {The Thirty-ninth Annual Conference on Neural Information Processing Systems},
	url          = {https://openreview.net/forum?id=yfcpdY4gMP}
}
