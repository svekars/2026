@article{01,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@article{02,
  title={Gymnasium: A standard interface for reinforcement learning environments},
  author={Towers, Mark and Kwiatkowski, Ariel and Terry, Jordan and Balis, John U and De Cola, Gianluca and Deleu, Tristan and Goul{\~a}o, Manuel and Kallinteris, Andreas and Krimmel, Markus and KG, Arjun and others},
  journal={arXiv preprint arXiv:2407.17032},
  year={2024}
}


@article{03,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{04,
  title={Cleanrl: High-quality single-file implementations of deep reinforcement learning algorithms},
  author={Huang, Shengyi and Dossa, Rousslan Fernand Julien and Ye, Chang and Braga, Jeff and Chakraborty, Dipam and Mehta, Kinal and Ara{\~A}{\v{s}}jo, Jo{\~A}{\c{G}}o GM},
  journal={Journal of Machine Learning Research},
  volume={23},
  number={274},
  pages={1--18},
  year={2022}
}

@article{05,
  title={Accelerating the machine learning lifecycle with MLflow.},
  author={Zaharia, Matei and Chen, Andrew and Davidson, Aaron and Ghodsi, Ali and Hong, Sue Ann and Konwinski, Andy and Murching, Siddharth and Nykodym, Tomas and Ogilvie, Paul and Parkhe, Mani and others},
  journal={IEEE Data Eng. Bull.},
  volume={41},
  number={4},
  pages={39--45},
  year={2018}
}

@inproceedings{06,
  title={Optuna: A next-generation hyperparameter optimization framework},
  author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={2623--2631},
  year={2019}
}

@article{07,
  title={A tutorial on Bayesian optimization},
  author={Frazier, Peter I},
  journal={arXiv preprint arXiv:1807.02811},
  year={2018}
}

@article{08,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  journal={Advances in neural information processing systems},
  volume={24},
  year={2011}
}

@inproceedings{09,
  title={Sequential model-based optimization for general algorithm configuration},
  author={Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  booktitle={International conference on learning and intelligent optimization},
  pages={507--523},
  year={2011},
  organization={Springer}
}

@inproceedings{10,
  title={Metis: Robustly tuning tail latencies of cloud systems},
  author={Li, Zhao Lucis and Liang, Chieh-Jan Mike and He, Wenjia and Zhu, Lianjie and Dai, Wenjun and Jiang, Jin and Sun, Guangzhong},
  booktitle={2018 USENIX Annual Technical Conference (USENIX ATC 18)},
  pages={981--992},
  year={2018}
}

@article{11,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt Jr, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@article{12,
  title={Genetic algorithms for hyperparameter optimization in predictive business process monitoring},
  author={Di Francescomarino, Chiara and Dumas, Marlon and Federici, Marco and Ghidini, Chiara and Maggi, Fabrizio Maria and Rizzi, Williams and Simonetto, Luca},
  journal={Information Systems},
  volume={74},
  pages={67--83},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{13,
  title={Particle swarm optimization},
  author={Kennedy, James and Eberhart, Russell},
  booktitle={Proceedings of ICNN'95-international conference on neural networks},
  volume={4},
  pages={1942--1948},
  year={1995},
  organization={ieee}
}

@article{14,
  title={Population based training of neural networks},
  author={Jaderberg, Max and Dalibard, Valentin and Osindero, Simon and Czarnecki, Wojciech M and Donahue, Jeff and Razavi, Ali and Vinyals, Oriol and Green, Tim and Dunning, Iain and Simonyan, Karen and others},
  journal={arXiv preprint arXiv:1711.09846},
  year={2017}
}

@inproceedings{15,
  title={Successive halving top-k operator},
  author={Pietruszka, Micha{\l} and Borchmann, {\L}ukasz and Grali{\'n}ski, Filip},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={18},
  pages={15869--15870},
  year={2021}
}

@article{16,
  title={Hyperband: A novel bandit-based approach to hyperparameter optimization},
  author={Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={185},
  pages={1--52},
  year={2018}
}

@inproceedings{17,
  title={BOHB: Robust and efficient hyperparameter optimization at scale},
  author={Falkner, Stefan and Klein, Aaron and Hutter, Frank},
  booktitle={International conference on machine learning},
  pages={1437--1446},
  year={2018},
  organization={PMLR}
}

@incollection{18,
  title={PyTorch},
  author={Imambi, Sagar and Prakash, Kolla Bhanu and Kanagachidambaresan, GR},
  booktitle={Programming with TensorFlow: solution for edge computing applications},
  pages={87--104},
  year={2021},
  publisher={Springer}
}

@article{19,
  title={Jax: Autograd and xla},
  author={Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and others},
  journal={Astrophysics Source Code Library},
  pages={ascl--2111},
  year={2021}
}

@article{20,
  title={Flax: A neural network library and ecosystem for JAX, 2020},
  author={Heek, Jonathan and Levskaya, Anselm and Oliver, Avital and Ritter, Marvin and Rondepierre, Bertrand and Steiner, Andreas and van Zee, Marc},
  journal={URL http://github. com/google/flax},
  volume={1},
  year={2020}
}


@article{21,
  title={The DeepMind JAX Ecosystem},
  author={DeepMind, Igor Babuschkin and Baumli, Kate and Bell, Alison and Bhupatiraju, Surya and Bruce, Jake and Buchlovsky, Peter and Budden, David and Cai, Trevor and Clark, Aidan and Danihelka, Ivo and others},
  journal={URL http://github. com/google-deepmind},
  year={2020}
}

@article{22,
  title={Brax--a differentiable physics engine for large scale rigid body simulation},
  author={Freeman, C Daniel and Frey, Erik and Raichuk, Anton and Girgin, Sertan and Mordatch, Igor and Bachem, Olivier},
  journal={arXiv preprint arXiv:2106.13281},
  year={2021}
}

@article{23,
  title={Dopamine: A research framework for deep reinforcement learning},
  author={Castro, Pablo Samuel and Moitra, Subhodeep and Gelada, Carles and Kumar, Saurabh and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1812.06110},
  year={2018}
}

@book{24,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G and others},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

