@article{zhong2025language,
  title={Language Lives in Sparse Dimensions: Toward Interpretable and Efficient Multilingual Control for Large Language Models},
  author={Zhong, Chengzhi and Cheng, Fei and Liu, Qianying and Murawaki, Yugo and Chu, Chenhui and Kurohashi, Sadao},
  journal={arXiv preprint arXiv:2510.07213},
  year={2025}
}

@inproceedings{qi-etal-2025-models,
    title = "When Models Reason in Your Language: Controlling Thinking Language Comes at the Cost of Accuracy",
    author = "Qi, Jirui  and
      Chen, Shan  and
      Xiong, Zidi  and
      Fern{\'a}ndez, Raquel  and
      Bitterman, Danielle  and
      Bisazza, Arianna",
    editor = "Christodoulopoulos, Christos  and
      Chakraborty, Tanmoy  and
      Rose, Carolyn  and
      Peng, Violet",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2025",
    month = nov,
    year = "2025",
    address = "Suzhou, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-emnlp.1103/",
    doi = "10.18653/v1/2025.findings-emnlp.1103",
    pages = "20279--20296",
    ISBN = "979-8-89176-335-7",
    abstract = "Recent Large Reasoning Models (LRMs) with thinking traces have shown strong performance on English reasoning tasks. However, the extent to which LRMs can think in other languages is less studied. This is as important as answer accuracy for real-world applications since users may find the thinking trace useful for oversight only if expressed in their languages. In this work, we comprehensively evaluate two leading families of LRMs on our established benchmark XReasoning. Surprisingly, even the most advanced models often revert to English or produce fragmented reasoning in other languages, revealing a substantial gap in the capability of thinking in non-English languages. Promoting models to reason in the user{'}s language via prompt hacking enhances readability and oversight. This could gain user trust, but reduces answer accuracy, exposing an important trade-off. We further demonstrate that targeted post-training, even with just 100 instances, can mitigate this language mismatch, although accuracy is still degraded. Our results reveal the limited multilingual reasoning capabilities of current LRMs and suggest directions for future research. All code and datasets are released at https://github.com/Betswish/mCoT-XReasoning."
}

@article{yong2025crosslingual,
  title={Crosslingual reasoning through test-time scaling},
  author={Yong, Zheng-Xin and Adilazuarda, M Farid and Mansurov, Jonibek and Zhang, Ruochen and Muennighoff, Niklas and Eickhoff, Carsten and Winata, Genta Indra and Kreutzer, Julia and Bach, Stephen H and Aji, Alham Fikri},
  journal={arXiv preprint arXiv:2505.05408},
  year={2025}
}

@article{kim2025one,
  title={One ruler to measure them all: Benchmarking multilingual long-context language models},
  author={Kim, Yekyung and Russell, Jenna and Karpinska, Marzena and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2503.01996},
  year={2025}
}

@inproceedings{
    ye2025limo,
    title={{LIMO}: Less is More for Reasoning},
    author={Yixin Ye and Zhen Huang and Yang Xiao and Ethan Chern and Shijie Xia and Pengfei Liu},
    booktitle={Second Conference on Language Modeling},
    year={2025},
    url={https://openreview.net/forum?id=T2TZ0RY4Zk}
}

@article{yu2025dapo,
  title={Dapo: An open-source llm reinforcement learning system at scale},
  author={Yu, Qiying and Zhang, Zheng and Zhu, Ruofei and Yuan, Yufeng and Zuo, Xiaochen and Yue, Yu and Dai, Weinan and Fan, Tiantian and Liu, Gaohong and Liu, Lingjun and others},
  journal={arXiv preprint arXiv:2503.14476},
  year={2025}
}

@article{rastogi2025magistral,
  title={Magistral},
  author={Rastogi, Abhinav and Jiang, Albert Q and Lo, Andy and Berrada, Gabrielle and Lample, Guillaume and Rute, Jason and Barmentlo, Joep and Yadav, Karmesh and Khandelwal, Kartik and Chandu, Khyathi Raghavi and others},
  journal={arXiv preprint arXiv:2506.10910},
  year={2025}
}

@misc{deepseekai2025deepseekr1distillqwen7b,
  title        = {DeepSeek-R1-Distill-Qwen-7B},
  author       = {DeepSeek-AI},
  year         = {2025},
  howpublished = {\url{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B}},
  note         = {Model card on Hugging Face},
}

@article{aggarwal2025optimalthinkingbench,
  title={Optimalthinkingbench: Evaluating over and underthinking in llms},
  author={Aggarwal, Pranjal and Kim, Seungone and Lanchantin, Jack and Welleck, Sean and Weston, Jason and Kulikov, Ilia and Saha, Swarnadeep},
  journal={arXiv preprint arXiv:2508.13141},
  year={2025}
}

@inproceedings{ustun-etal-2024-aya,
    title = "Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model",
    author = {{\"U}st{\"u}n, Ahmet  and
      Aryabumi, Viraat  and
      Yong, Zheng  and
      Ko, Wei-Yin  and
      D{'}souza, Daniel  and
      Onilude, Gbemileke  and
      Bhandari, Neel  and
      Singh, Shivalika  and
      Ooi, Hui-Lee  and
      Kayid, Amr  and
      Vargus, Freddie  and
      Blunsom, Phil  and
      Longpre, Shayne  and
      Muennighoff, Niklas  and
      Fadaee, Marzieh  and
      Kreutzer, Julia  and
      Hooker, Sara},
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.845/",
    doi = "10.18653/v1/2024.acl-long.845",
    pages = "15894--15939",
    abstract = "Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50{\%} are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages {---}{---} including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models."
}