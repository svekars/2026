@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{thomson1916,
author = {THOMSON, GODFREY H.},
title = {A HIERARCHY WITHOUT A GENERAL FACTOR},
journal = {British Journal of Psychology, 1904-1920},
volume = {8},
number = {3},
pages = {271-281},
doi = {https://doi.org/10.1111/j.2044-8295.1916.tb00133.x},
url = {https://bpspsychub.onlinelibrary.wiley.com/doi/abs/10.1111/j.2044-8295.1916.tb00133.x},
eprint = {https://bpspsychub.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2044-8295.1916.tb00133.x},
year = {1916}
}
@article{ilievski2025aligning,
  title={Aligning generalization between humans and machines},
  author={Ilievski, Filip and Hammer, Barbara and van Harmelen, Frank and Paassen, Benjamin and Saralajew, Sascha and Schmid, Ute and Biehl, Michael and Bolognesi, Marianna and Dong, Xin Luna and Gashteovski, Kiril and others},
  journal={Nature Machine Intelligence},
  pages={1--12},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{abdelkarim2025evaluating,
  title={Evaluating the Intelligence of large language models: A comparative study using verbal and visual IQ tests},
  author={Abdelkarim, Sherif and Lu, David and Flores, Dora-Luz and Jaeggi, Susanne and Baldi, Pierre},
  journal={Computers in Human Behavior: Artificial Humans},
  pages={100170},
  year={2025},
  publisher={Elsevier}
}

@article{kozlov2023ai,
  title={AI HAS HUMAN-LIKE ABILITY TO GENERALIZE},
  author={Kozlov, Max and Biever, Celeste},
  journal={Nature},
  volume={623},
  pages={2},
  year={2023}
}

@inproceedings{kiela2021dynabench,
  title={Dynabench: Rethinking benchmarking in NLP},
  author={Kiela, Douwe and Bartolo, Max and Nie, Yixin and Kaushik, Divyansh and Geiger, Atticus and Wu, Zhengxuan and Vidgen, Bertie and Prasad, Grusha and Singh, Amanpreet and Ringshia, Pratik and others},
  booktitle={Proceedings of the 2021 conference of the North American chapter of the Association for Computational Linguistics: human language technologies},
  pages={4110--4124},
  year={2021}
}

@article{hofmann2025fluid,
  title={Fluid language model benchmarking},
  author={Hofmann, Valentin and Heineman, David and Magnusson, Ian and Lo, Kyle and Dodge, Jesse and Sap, Maarten and Koh, Pang Wei and Wang, Chun and Hajishirzi, Hannaneh and Smith, Noah A},
  journal={arXiv preprint arXiv:2509.11106},
  year={2025}
}

@inproceedings{kim2025benchmark,
  title={Benchmark Profiling: Mechanistic Diagnosis of LLM Benchmarks},
  author={Kim, Dongjun and Shim, Gyuho and Chun, Yongchan and Kim, Minhyuk and Park, Chanjun and Lim, Heui-Seok},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing},
  pages={15646--15661},
  year={2025}
}

@article{hupkes2023taxonomy,
  title={A taxonomy and review of generalization research in NLP},
  author={Hupkes, Dieuwke and Giulianelli, Mario and Dankers, Verna and Artetxe, Mikel and Elazar, Yanai and Pimentel, Tiago and Christodoulopoulos, Christos and Lasri, Karim and Saphra, Naomi and Sinclair, Arabella and others},
  journal={Nature Machine Intelligence},
  volume={5},
  number={10},
  pages={1161--1174},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{merlo2023blackbird,
  title={Blackbird language matrices (BLM), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?},
  author={Merlo, Paola},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2023},
  pages={8119--8152},
  year={2023}
}

@article{hendrycks2025definition,
  title={A Definition of AGI},
  author={Hendrycks, Dan and Song, Dawn and Szegedy, Christian and Lee, Honglak and Gal, Yarin and Brynjolfsson, Erik and Li, Sharon and Zou, Andy and Levine, Lionel and Han, Bo and others},
  journal={arXiv preprint arXiv:2510.18212},
  year={2025}
}

@article{mueller2024myth,
  title={The myth of AGI},
  author={Mueller, Milton},
  journal={Internet Governance Project},
  year={2024}
}

@inproceedings{blili2024unsocial,
  title={Unsocial Intelligence: An Investigation of the Assumptions of AGI Discourse},
  author={Blili-Hamelin, Borhane and Hancox-Li, Leif and Smart, Andrew},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  volume={7},
  pages={141--155},
  year={2024}
}

@incollection{mari2023philosophical,
  title={Philosophical perspectives on measurement},
  author={Mari, Luca and Wilson, Mark and Maul, Andrew},
  booktitle={Measurement across the sciences: Developing a shared concept system for measurement},
  pages={81--121},
  year={2023},
  publisher={Springer}
}

@article{10.1145/33447.33448,
author = {McCarthy, John},
title = {Generality in artificial intelligence},
year = {1987},
issue_date = {Dec. 1987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/33447.33448},
doi = {10.1145/33447.33448},
abstract = {My 1971 Turing Award Lecture was entitled "Generality in Artificial Intelligence." The topic turned out to have been overambitious in that I discovered I was unable to put my thoughts on the subject in a satisfactory written form at that time. It would have been better to have reviewed my previous work rather than attempt something new, but such was not my custom at that time.I am grateful to ACM for the opportunity to try again. Unfortunately for our science, although perhaps fortunately for this project, the problem of generality in artificial intelligence (AI) is almost as unsolved as ever, although we now have many ideas not available in 1971. This paper relies heavily on such ideas, but it is far from a full 1987 survey of approaches for achieving generality. Ideas are therefore discussed at a length proportional to my familiarity with them rather than according to some objective criterion.It was obvious in 1971 and even in 1958 that AI programs suffered from a lack of generality. It is still obvious; there are many more details. The first gross symptom is that a small addition to the idea of a program often involves a complete rewrite beginning with the data structures. Some progress has been made in modularizing data structures, but small modifications of the search strategies are even less likely to be accomplished without rewriting.Another symptom is no one knows how to make a general database of commonsense knowledge that could be used by any program that needed the knowledge. Along with other information, such a database would contain what a robot would need to know about the effects of moving objects around, what a person can be expected to know about his family, and the facts about buying and selling. This does not depend on whether the knowledge is to be expressed in a logical language or in some other formalism. When we take the logic approach to AI, lack of generality shows up in that the axioms we devise to express commonsense knowledge are too restricted in their applicability for a general commonsense database. In my opinion, getting a language for expressing general commonsense knowledge for inclusion in a general database is the key problem of generality in AI.Here are some ideas for achieving generality proposed both before and after 1971. I repeat my disclaimer of comprehensiveness.},
journal = {Commun. ACM},
month = dec,
pages = {1030–1035},
numpages = {6}
}

@article{zhang2024generalist,
  title={A generalist vision--language foundation model for diverse biomedical tasks},
  author={Zhang, Kai and Zhou, Rong and Adhikarla, Eashan and Yan, Zhiling and Liu, Yixin and Yu, Jun and Liu, Zhengliang and Chen, Xun and Davison, Brian D and Ren, Hui and others},
  journal={Nature Medicine},
  volume={30},
  number={11},
  pages={3129--3141},
  year={2024},
  publisher={Nature Publishing Group US New York}
}

@article{moor2023foundation,
  title={Foundation models for generalist medical artificial intelligence},
  author={Moor, Michael and Banerjee, Oishi and Abad, Zahra Shakeri Hossein and Krumholz, Harlan M and Leskovec, Jure and Topol, Eric J and Rajpurkar, Pranav},
  journal={Nature},
  volume={616},
  number={7956},
  pages={259--265},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{burton2024large,
  title={How large language models can reshape collective intelligence},
  author={Burton, Jason W and Lopez-Lopez, Ezequiel and Hechtlinger, Shahar and Rahwan, Zoe and Aeschbach, Samuel and Bakker, Michiel A and Becker, Joshua A and Berditchevskaia, Aleks and Berger, Julian and Brinkmann, Levin and others},
  journal={Nature human behaviour},
  volume={8},
  number={9},
  pages={1643--1655},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{steyvers2025large,
  title={What large language models know and what people think they know},
  author={Steyvers, Mark and Tejeda, Heliodoro and Kumar, Aakriti and Belem, Catarina and Karny, Sheer and Hu, Xinyue and Mayer, Lukas W and Smyth, Padhraic},
  journal={Nature Machine Intelligence},
  volume={7},
  number={2},
  pages={221--231},
  year={2025},
  publisher={Nature Publishing Group UK London}
}

@article{hernandez2021general,
  title={General intelligence disentangled via a generality metric for natural and artificial intelligence},
  author={Hern{\'a}ndez-Orallo, Jos{\'e} and Loe, Bao Sheng and Cheke, Lucy and Mart{\'\i}nez-Plumed, Fernando and {\'O} h{\'E}igeartaigh, Se{\'a}n},
  journal={Scientific reports},
  volume={11},
  number={1},
  pages={22822},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@article{allenspach2024neural,
  title={Neural multi-task learning in drug design},
  author={Allenspach, Stephan and Hiss, Jan A and Schneider, Gisbert},
  journal={Nature Machine Intelligence},
  volume={6},
  number={2},
  pages={124--137},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@article{zhang2021survey,
  title={A survey on multi-task learning},
  author={Zhang, Yu and Yang, Qiang},
  journal={IEEE transactions on knowledge and data engineering},
  volume={34},
  number={12},
  pages={5586--5609},
  year={2021},
  publisher={IEEE}
}

@inproceedings{sogaard-etal-2021-need,
    title = "We Need To Talk About Random Splits",
    author = "S{\o}gaard, Anders  and
      Ebert, Sebastian  and
      Bastings, Jasmijn  and
      Filippova, Katja",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.156/",
    doi = "10.18653/v1/2021.eacl-main.156",
    pages = "1823--1832",
    abstract = "(CITATION) argued for using random splits rather than standard splits in NLP experiments. We argue that random splits, like standard splits, lead to overly optimistic performance estimates. We can also split data in biased or adversarial ways, e.g., training on short sentences and evaluating on long ones. Biased sampling has been used in domain adaptation to simulate real-world drift; this is known as the covariate shift assumption. In NLP, however, even worst-case splits, maximizing bias, often under-estimate the error observed on new samples of in-domain data, i.e., the data that models should minimally generalize to at test time. This invalidates the covariate shift assumption. Instead of using multiple random splits, future benchmarks should ideally include multiple, independent test sets instead; if infeasible, we argue that multiple biased splits leads to more realistic performance estimates than multiple random splits."
}

@article{simon1976computer,
  title={Computer science as empirical inquiry: symbols and search},
  author={Simon, Herbert A and Newell, Allen},
  journal={Communications of the ACM},
  volume={19},
  number={3},
  pages={11--126},
  year={1976}
}

@article{nisbett2001culture,
  title={Culture and systems of thought: holistic versus analytic cognition.},
  author={Nisbett, Richard E and Peng, Kaiping and Choi, Incheol and Norenzayan, Ara},
  journal={Psychological review},
  volume={108},
  number={2},
  pages={291},
  year={2001},
  publisher={American Psychological Association}
}

@article{sternberg2004intelligence,
  title={Intelligence and culture: How culture shapes what intelligence means, and the implications for a science of well--being},
  author={Sternberg, Robert J and Grigorenko, Elena L},
  journal={Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences},
  volume={359},
  number={1449},
  pages={1427--1434},
  year={2004},
  publisher={The Royal Society}
}

@article{anderson2010neural,
  title={Neural reuse: A fundamental organizational principle of the brain},
  author={Anderson, Michael L},
  journal={Behavioral and brain sciences},
  volume={33},
  number={4},
  pages={245--266},
  year={2010},
  publisher={Cambridge University Press}
}

@article{pessoa2014understanding,
  title={Understanding brain networks and brain organization},
  author={Pessoa, Luiz},
  journal={Physics of life reviews},
  volume={11},
  number={3},
  pages={400--435},
  year={2014},
  publisher={Elsevier}
}

@article{bola2015dynamic,
  title={Dynamic reorganization of brain functional networks during cognition},
  author={Bola, Micha{\l} and Sabel, Bernhard A},
  journal={Neuroimage},
  volume={114},
  pages={398--413},
  year={2015},
  publisher={Elsevier}
}

@article{international1972definition,
  title={On Definition of Artificial Intelligence},
  author={International Centre for Mechanical Sciences; International Federation for the Theory of Machines and Mechanisms and Radchenko, AN and Yurevich, EI},
  journal={On Theory and Practice of Robots and Manipulators},
  pages={91--101},
  year={1972},
  publisher={Springer}
}

@article{simmons1988artificial,
  title={Artificial intelligence-definition and practice},
  author={Simmons, Asa B and Chappell, Steven G},
  journal={IEEE journal of oceanic engineering},
  volume={13},
  number={2},
  pages={14--42},
  year={1988},
  publisher={IEEE}
}

@article{muller2016future,
  title={Future progress in artificial intelligence: A survey of expert opinion},
  author={M{\"u}ller, Vincent C and Bostrom, Nick},
  journal={Fundamental issues of artificial intelligence},
  pages={555--572},
  year={2016},
  publisher={Springer}
}

@article{
srivastava2023beyond,
title={Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
author={Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R. Brown and Adam Santoro and Aditya Gupta and Adri{\`a} Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W. Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S. Iyer and Anders Johan Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlm{\"u}ller and Andrew M. Dai and Andrew La and Andrew Kyle Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karaka{\c{s}} and B. Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bart{\l}omiej Bojanowski and Batuhan {\"O}zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and Cesar Ferri and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Christopher Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E. Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and C. Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu{\'\i} Gonz{\'a}lez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodol{\`a} and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Mart{\'\i}nez-Plumed and Francesca Happ{\'e} and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germ{\`a}n Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Xinyue Wang and Gonzalo Jaimovitch-Lopez and Gregor Betz and Guy Gur-Ari and Hana Galijasevic and Hannah Kim and Hannah Rashkin and Hannaneh Hajishirzi and Harsh Mehta and Hayden Bogar and Henry Francis Anthony Shevlin and Hinrich Schuetze and Hiromu Yakura and Hongming Zhang and Hugh Mee Wong and Ian Ng and Isaac Noble and Jaap Jumelet and Jack Geissinger and Jackson Kernion and Jacob Hilton and Jaehoon Lee and Jaime Fern{\'a}ndez Fisac and James B Simon and James Koppel and James Zheng and James Zou and Jan Kocon and Jana Thompson and Janelle Wingfield and Jared Kaplan and Jarema Radom and Jascha Sohl-Dickstein and Jason Phang and Jason Wei and Jason Yosinski and Jekaterina Novikova and Jelle Bosscher and Jennifer Marsh and Jeremy Kim and Jeroen Taal and Jesse Engel and Jesujoba Alabi and Jiacheng Xu and Jiaming Song and Jillian Tang and Joan Waweru and John Burden and John Miller and John U. Balis and Jonathan Batchelder and Jonathan Berant and J{\"o}rg Frohberg and Jos Rozen and Jose Hernandez-Orallo and Joseph Boudeman and Joseph Guerr and Joseph Jones and Joshua B. Tenenbaum and Joshua S. Rule and Joyce Chua and Kamil Kanclerz and Karen Livescu and Karl Krauth and Karthik Gopalakrishnan and Katerina Ignatyeva and Katja Markert and Kaustubh Dhole and Kevin Gimpel and Kevin Omondi and Kory Wallace Mathewson and Kristen Chiafullo and Ksenia Shkaruta and Kumar Shridhar and Kyle McDonell and Kyle Richardson and Laria Reynolds and Leo Gao and Li Zhang and Liam Dugan and Lianhui Qin and Lidia Contreras-Ochando and Louis-Philippe Morency and Luca Moschella and Lucas Lam and Lucy Noble and Ludwig Schmidt and Luheng He and Luis Oliveros-Col{\'o}n and Luke Metz and L{\"u}tfi Kerem Senel and Maarten Bosma and Maarten Sap and Maartje Ter Hoeve and Maheen Farooqi and Manaal Faruqui and Mantas Mazeika and Marco Baturan and Marco Marelli and Marco Maru and Maria Jose Ramirez-Quintana and Marie Tolkiehn and Mario Giulianelli and Martha Lewis and Martin Potthast and Matthew L Leavitt and Matthias Hagen and M{\'a}ty{\'a}s Schubert and Medina Orduna Baitemirova and Melody Arnaud and Melvin McElrath and Michael Andrew Yee and Michael Cohen and Michael Gu and Michael Ivanitskiy and Michael Starritt and Michael Strube and Micha{\l} Sw{\k{e}}drowski and Michele Bevilacqua and Michihiro Yasunaga and Mihir Kale and Mike Cain and Mimee Xu and Mirac Suzgun and Mitch Walker and Mo Tiwari and Mohit Bansal and Moin Aminnaseri and Mor Geva and Mozhdeh Gheini and Mukund Varma T and Nanyun Peng and Nathan Andrew Chi and Nayeon Lee and Neta Gur-Ari Krakover and Nicholas Cameron and Nicholas Roberts and Nick Doiron and Nicole Martinez and Nikita Nangia and Niklas Deckers and Niklas Muennighoff and Nitish Shirish Keskar and Niveditha S. Iyer and Noah Constant and Noah Fiedel and Nuan Wen and Oliver Zhang and Omar Agha and Omar Elbaghdadi and Omer Levy and Owain Evans and Pablo Antonio Moreno Casares and Parth Doshi and Pascale Fung and Paul Pu Liang and Paul Vicol and Pegah Alipoormolabashi and Peiyuan Liao and Percy Liang and Peter W Chang and Peter Eckersley and Phu Mon Htut and Pinyu Hwang and Piotr Mi{\l}kowski and Piyush Patil and Pouya Pezeshkpour and Priti Oli and Qiaozhu Mei and Qing Lyu and Qinlang Chen and Rabin Banjade and Rachel Etta Rudolph and Raefer Gabriel and Rahel Habacker and Ramon Risco and Rapha{\"e}l Milli{\`e}re and Rhythm Garg and Richard Barnes and Rif A. Saurous and Riku Arakawa and Robbe Raymaekers and Robert Frank and Rohan Sikand and Roman Novak and Roman Sitelew and Ronan Le Bras and Rosanne Liu and Rowan Jacobs and Rui Zhang and Russ Salakhutdinov and Ryan Andrew Chi and Seungjae Ryan Lee and Ryan Stovall and Ryan Teehan and Rylan Yang and Sahib Singh and Saif M. Mohammad and Sajant Anand and Sam Dillavou and Sam Shleifer and Sam Wiseman and Samuel Gruetter and Samuel R. Bowman and Samuel Stern Schoenholz and Sanghyun Han and Sanjeev Kwatra and Sarah A. Rous and Sarik Ghazarian and Sayan Ghosh and Sean Casey and Sebastian Bischoff and Sebastian Gehrmann and Sebastian Schuster and Sepideh Sadeghi and Shadi Hamdan and Sharon Zhou and Shashank Srivastava and Sherry Shi and Shikhar Singh and Shima Asaadi and Shixiang Shane Gu and Shubh Pachchigar and Shubham Toshniwal and Shyam Upadhyay and Shyamolima Shammie Debnath and Siamak Shakeri and Simon Thormeyer and Simone Melzi and Siva Reddy and Sneha Priscilla Makini and Soo-Hwan Lee and Spencer Torene and Sriharsha Hatwar and Stanislas Dehaene and Stefan Divic and Stefano Ermon and Stella Biderman and Stephanie Lin and Stephen Prasad and Steven Piantadosi and Stuart Shieber and Summer Misherghi and Svetlana Kiritchenko and Swaroop Mishra and Tal Linzen and Tal Schuster and Tao Li and Tao Yu and Tariq Ali and Tatsunori Hashimoto and Te-Lin Wu and Th{\'e}o Desbordes and Theodore Rothschild and Thomas Phan and Tianle Wang and Tiberius Nkinyili and Timo Schick and Timofei Kornev and Titus Tunduny and Tobias Gerstenberg and Trenton Chang and Trishala Neeraj and Tushar Khot and Tyler Shultz and Uri Shaham and Vedant Misra and Vera Demberg and Victoria Nyamai and Vikas Raunak and Vinay Venkatesh Ramasesh and vinay uday prabhu and Vishakh Padmakumar and Vivek Srikumar and William Fedus and William Saunders and William Zhang and Wout Vossen and Xiang Ren and Xiaoyu Tong and Xinran Zhao and Xinyi Wu and Xudong Shen and Yadollah Yaghoobzadeh and Yair Lakretz and Yangqiu Song and Yasaman Bahri and Yejin Choi and Yichi Yang and Sophie Hao and Yifu Chen and Yonatan Belinkov and Yu Hou and Yufang Hou and Yuntao Bai and Zachary Seid and Zhuoye Zhao and Zijian Wang and Zijie J. Wang and Zirui Wang and Ziyi Wu},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=uyTL5Bvosj},
note={Featured Certification}
}

@article{bommasani2023holistic,
  title={Holistic evaluation of language models},
  author={Bommasani, Rishi and Liang, Percy and Lee, Tony},
  journal={Annals of the New York Academy of Sciences},
  volume={1525},
  number={1},
  pages={140--146},
  year={2023},
  publisher={Wiley Online Library}
}

@inproceedings{
sanh2022multitask,
title={Multitask Prompted Training Enables Zero-Shot Task Generalization},
author={Victor Sanh and Albert Webson and Colin Raffel and Stephen Bach and Lintang Sutawika and Zaid Alyafeai and Antoine Chaffin and Arnaud Stiegler and Arun Raja and Manan Dey and M Saiful Bari and Canwen Xu and Urmish Thakker and Shanya Sharma Sharma and Eliza Szczechla and Taewoon Kim and Gunjan Chhablani and Nihal Nayak and Debajyoti Datta and Jonathan Chang and Mike Tian-Jian Jiang and Han Wang and Matteo Manica and Sheng Shen and Zheng Xin Yong and Harshit Pandey and Rachel Bawden and Thomas Wang and Trishala Neeraj and Jos Rozen and Abheesht Sharma and Andrea Santilli and Thibault Fevry and Jason Alan Fries and Ryan Teehan and Teven Le Scao and Stella Biderman and Leo Gao and Thomas Wolf and Alexander M Rush},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=9Vrb9D0WI4}
}

@article{pellert2024ai,
  title={Ai psychometrics: Assessing the psychological profiles of large language models through psychometric inventories},
  author={Pellert, Max and Lechner, Clemens M and Wagner, Claudia and Rammstedt, Beatrice and Strohmaier, Markus},
  journal={Perspectives on Psychological Science},
  volume={19},
  number={5},
  pages={808--826},
  year={2024},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@article{cai2025mm,
  title={MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models},
  author={Cai, Huanqia and Yang, Yijun and Hu, Winston},
  journal={arXiv preprint arXiv:2502.00698},
  year={2025}
}

@article{huang2024measuring,
  title={Measuring the iq of mainstream large language models in chinese using the wechsler adult intelligence scale},
  author={Huang, Jingjing and Li, Ou},
  journal={Authorea Preprints},
  year={2024},
  publisher={Authorea}
}

@inproceedings{akyurek-etal-2022-challenges,
    title = "Challenges in Measuring Bias via Open-Ended Language Generation",
    author = {Aky{\"u}rek, Afra Feyza  and
      Kocyigit, Muhammed Yusuf  and
      Paik, Sejin  and
      Wijaya, Derry Tanti},
    editor = "Hardmeier, Christian  and
      Basta, Christine  and
      Costa-juss{\`a}, Marta R.  and
      Stanovsky, Gabriel  and
      Gonen, Hila",
    booktitle = "Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gebnlp-1.9/",
    doi = "10.18653/v1/2022.gebnlp-1.9",
    pages = "76--76",
    abstract = "Researchers have devised numerous ways to quantify social biases vested in pretrained language models. As some language models are capable of generating coherent completions given a set of textual prompts, several prompting datasets have been proposed to measure biases between social groups{---}posing language generation as a way of identifying biases. In this opinion paper, we analyze how specific choices of prompt sets, metrics, automatic tools and sampling strategies affect bias results. We find out that the practice of measuring biases through text completion is prone to yielding contradicting results under different experiment settings. We additionally provide recommendations for reporting biases in open-ended language generation for a more complete outlook of biases exhibited by a given language model. Code to reproduce the results is released under \url{https://github.com/feyzaakyurek/bias-textgen}."
}

@inproceedings{blodgett-etal-2021-stereotyping,
    title = "Stereotyping {N}orwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets",
    author = "Blodgett, Su Lin  and
      Lopez, Gilsinia  and
      Olteanu, Alexandra  and
      Sim, Robert  and
      Wallach, Hanna",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.81/",
    doi = "10.18653/v1/2021.acl-long.81",
    pages = "1004--1015",
    abstract = "Auditing NLP systems for computational harms like surfacing stereotypes is an elusive goal. Several recent efforts have focused on benchmark datasets consisting of pairs of contrastive sentences, which are often accompanied by metrics that aggregate an NLP system`s behavior on these pairs into measurements of harms. We examine four such benchmarks constructed for two NLP tasks: language modeling and coreference resolution. We apply a measurement modeling lens{---}originating from the social sciences{---}to inventory a range of pitfalls that threaten these benchmarks' validity as measurement models for stereotyping. We find that these benchmarks frequently lack clear articulations of what is being measured, and we highlight a range of ambiguities and unstated assumptions that affect how these benchmarks conceptualize and operationalize stereotyping."
}

@inproceedings{blodgett-etal-2024-human,
    title = "Human-Centered Evaluation of Language Technologies",
    author = "Blodgett, Su Lin  and
      Cheung, Jackie Chi Kit  and
      Liao, Vera  and
      Xiao, Ziang",
    editor = "Li, Jessy  and
      Liu, Fei",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-tutorials.6/",
    doi = "10.18653/v1/2024.emnlp-tutorials.6",
    pages = "39--43",
    abstract = "Evaluation is a cornerstone topic in NLP. However, many criticisms have been raised about the community`s evaluation practices, including a lack of human-centered considerations about people`s needs for language technologies and their actual impact on people. This {\textquotedblleft}evaluation crisis{\textquotedblright} is exacerbated by the recent development of large generative models with diverse and uncertain capabilities. This tutorial aims to inspire more human-centered evaluation in NLP by introducing perspectives and methodologies from human-computer interaction (HCI), a field concerned primarily with the design and evaluation of technologies. The tutorial will start with an overview of current NLP evaluation practices and their limitations, then introduce the {\textquotedblleft}toolbox of evaluation methods{\textquotedblright} from HCI with varying considerations such as what to evaluate for, how generalizable the results are to the real-world contexts, and pragmatic costs to conduct the evaluation. The tutorial will also encourage reflection on how these HCI perspectives and methodologies can complement NLP evaluation through Q{\&}A discussions and a hands-on exercise."
}

@article{ott2022mapping,
  title={Mapping global dynamics of benchmark creation and saturation in artificial intelligence},
  author={Ott, Simon and Barbosa-Silva, Adriano and Blagec, Kathrin and Brauner, Jan and Samwald, Matthias},
  journal={Nature Communications},
  volume={13},
  number={1},
  pages={6793},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{biderman2024lessons,
  title={Lessons from the trenches on reproducible evaluation of language models},
  author={Biderman, Stella and Schoelkopf, Hailey and Sutawika, Lintang and Gao, Leo and Tow, Jonathan and Abbasi, Baber and Aji, Alham Fikri and Ammanamanchi, Pawan Sasanka and Black, Sidney and Clive, Jordan and others},
  journal={arXiv preprint arXiv:2405.14782},
  year={2024}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{legg2005universal,
  title={A universal measure of intelligence for artificial agents},
  author={Legg, Shane and Hutter, Marcus and others},
  booktitle={International Joint Conference on Artificial Intelligence},
  volume={19},
  pages={1509},
  year={2005},
  organization={LAWRENCE ERLBAUM ASSOCIATES LTD}
}

@article{gershman2015computational,
  title={Computational rationality: A converging paradigm for intelligence in brains, minds, and machines},
  author={Gershman, Samuel J and Horvitz, Eric J and Tenenbaum, Joshua B},
  journal={Science},
  volume={349},
  number={6245},
  pages={273--278},
  year={2015},
  publisher={American Association for the Advancement of Science}
}

@article{kryven2021plans,
  title={Plans or outcomes: How do we attribute intelligence to others?},
  author={Kryven, Marta and Ullman, Tomer D and Cowan, William and Tenenbaum, Joshua B},
  journal={Cognitive Science},
  volume={45},
  number={9},
  pages={e13041},
  year={2021},
  publisher={Wiley Online Library}
}

@article{gignac2015raven,
  title={Raven's is not a pure measure of general intelligence: Implications for g factor theory and the brief measurement of g},
  author={Gignac, Gilles E},
  journal={Intelligence},
  volume={52},
  pages={71--79},
  year={2015},
  publisher={Elsevier}
}

@article{feng2024how,
title={How Far Are We From {AGI}: Are {LLM}s All We Need?},
author={Tao Feng and Chuanyang Jin and Jingyu Liu and Kunlun Zhu and Haoqin Tu and Zirui Cheng and Guanyu Lin and Jiaxuan You},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2024},
url={https://openreview.net/forum?id=H2ZKqfNd0U},
note={Survey Certification}
}

@inproceedings{seferis2024benchmark,
  title={How to benchmark AGI: the Adversarial Game},
  author={Seferis, Emmanouil},
  booktitle={ICLR 2024 Workshop: How Far Are We From AGI},
  year={2024}
}

@inproceedings{you2024far,
  title={How far are we from agi},
  author={You, Jiaxuan and Liu, Ge and Li, Yunzhu and Han, Song and Song, Dawn},
  booktitle={ICLR 2024 Workshops},
  year={2024}
}



@misc{mitchell2024debates,
  title={Debates on the nature of artificial general intelligence},
  author={Mitchell, Melanie},
  journal={Science},
  volume={383},
  number={6689},
  pages={eado7069},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{kinzler2007core,
  title={Core systems in human cognition},
  author={Kinzler, Katherine D and Spelke, Elizabeth S},
  journal={Progress in brain research},
  volume={164},
  pages={257--264},
  year={2007},
  publisher={Elsevier}
}

@article{spelke2007core,
  title={Core knowledge},
  author={Spelke, Elizabeth S and Kinzler, Katherine D},
  journal={Developmental science},
  volume={10},
  number={1},
  pages={89--96},
  year={2007},
  publisher={Wiley Online Library}
}

@incollection{schmidhuber2007godel,
  title={G{\"o}del machines: Fully self-referential optimal universal self-improvers},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Artificial general intelligence},
  pages={199--226},
  year={2007},
  publisher={Springer}
}

@inproceedings{schmidhuber2011artificial,
  title={Artificial general intelligence},
  author={Schmidhuber, J{\"u}rgen and Thorisson, Kristinn R and Looks, Moshe},
  booktitle={Proceedings},
  year={2011},
  organization={Springer}
}

@inproceedings{
zhang2024when,
title={When Scaling Meets {LLM} Finetuning: The Effect of Data, Model and Finetuning Method},
author={Biao Zhang and Zhongtao Liu and Colin Cherry and Orhan Firat},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=5HCnKDeTws}
}

@inproceedings{
snell2025scaling,
title={Scaling {LLM} Test-Time Compute Optimally Can be More Effective than Scaling Parameters for Reasoning},
author={Charlie Victor Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=4FWAwZtd2n}
}

@article{tocchetti2025ai,
  title={Ai robustness: a human-centered perspective on technological challenges and opportunities},
  author={Tocchetti, Andrea and Corti, Lorenzo and Balayn, Agathe and Yurrita, Mireia and Lippmann, Philip and Brambilla, Marco and Yang, Jie},
  journal={ACM Computing Surveys},
  volume={57},
  number={6},
  pages={1--38},
  year={2025},
  publisher={ACM New York, NY}
}


@inproceedings{liu-etal-2024-ecbd,
    title = "{ECBD}: Evidence-Centered Benchmark Design for {NLP}",
    author = "Liu, Yu Lu  and
      Blodgett, Su Lin  and
      Cheung, Jackie  and
      Liao, Q. Vera  and
      Olteanu, Alexandra  and
      Xiao, Ziang",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.861/",
    doi = "10.18653/v1/2024.acl-long.861",
    pages = "16349--16365",
    abstract = "Benchmarking is seen as critical to assessing progress in NLP. However, creating a benchmark involves many design decisions (e.g., which datasets to include, which metrics to use) that often rely on tacit, untested assumptions about what the benchmark is intended to measure or is actually measuring. There is currently no principled way of analyzing these decisions and how they impact the validity of the benchmark`s measurements. To address this gap, we draw on evidence-centered design in educational assessments and propose Evidence-Centered Benchmark Design (ECBD), a framework which formalizes the benchmark design process into five modules. ECBD specifies the role each module plays in helping practitioners collect evidence about capabilities of interest. Specifically, each module requires benchmark designers to describe, justify, and support benchmark design choices{---}e.g., clearly specifying the capabilities the benchmark aims to measure or how evidence about those capabilities is collected from model responses. To demonstrate the use of ECBD, we conduct case studies with three benchmarks: BoolQ, SuperGLUE, and HELM. Our analysis reveals common trends in benchmark design and documentation that could threaten the validity of benchmarks' measurements."
}

@inproceedings{10.5555/3600270.3602070,
author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed H. and Le, Quoc V. and Zhou, Denny},
title = {Chain-of-thought prompting elicits reasoning in large language models},
year = {2022},
isbn = {9781713871088},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.},
booktitle = {Proceedings of the 36th International Conference on Neural Information Processing Systems},
articleno = {1800},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '22}
}

@article{valmeekam2023planning,
  title={On the planning abilities of large language models-a critical investigation},
  author={Valmeekam, Karthik and Marquez, Matthew and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={75993--76005},
  year={2023}
}

@article{valmeekam2023planbench,
  title={Planbench: An extensible benchmark for evaluating large language models on planning and reasoning about change},
  author={Valmeekam, Karthik and Marquez, Matthew and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={38975--38987},
  year={2023}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{morishita2024enhancing,
  title={Enhancing reasoning capabilities of llms via principled synthetic logic corpus},
  author={Morishita, Terufumi and Morio, Gaku and Yamaguchi, Atsuki and Sogawa, Yasuhiro},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={73572--73604},
  year={2024}
}

@article{ilic2024evidence,
  title={Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?},
  author={Ili{\'c}, David and Gignac, Gilles E},
  journal={Intelligence},
  volume={106},
  pages={101858},
  year={2024},
  publisher={Elsevier}
}

@inproceedings{longpre2023flan,
  title={The flan collection: Designing data and methods for effective instruction tuning},
  author={Longpre, Shayne and Hou, Le and Vu, Tu and Webson, Albert and Chung, Hyung Won and Tay, Yi and Zhou, Denny and Le, Quoc V and Zoph, Barret and Wei, Jason and others},
  booktitle={International Conference on Machine Learning},
  pages={22631--22648},
  year={2023},
  organization={PMLR}
}

@article{iyer2022opt,
  title={Opt-iml: Scaling language model instruction meta learning through the lens of generalization},
  author={Iyer, Srinivasan and Lin, Xi Victoria and Pasunuru, Ramakanth and Mihaylov, Todor and Simig, Daniel and Yu, Ping and Shuster, Kurt and Wang, Tianlu and Liu, Qing and Koura, Punit Singh and others},
  journal={arXiv preprint arXiv:2212.12017},
  year={2022}
}

@article{kazemi2025big,
  title={Big-bench extra hard},
  author={Kazemi, Mehran and Fatemi, Bahare and Bansal, Hritik and Palowitch, John and Anastasiou, Chrysovalantis and Mehta, Sanket Vaibhav and Jain, Lalit K and Aglietti, Virginia and Jindal, Disha and Chen, Peter and others},
  journal={arXiv preprint arXiv:2502.19187},
  year={2025}
}

@article{helm2020machine,
  title={Machine learning and artificial intelligence: definitions, applications, and future directions},
  author={Helm, J Matthew and Swiergosz, Andrew M and Haeberle, Heather S and Karnuta, Jaret M and Schaffer, Jonathan L and Krebs, Viktor E and Spitzer, Andrew I and Ramkumar, Prem N},
  journal={Current reviews in musculoskeletal medicine},
  volume={13},
  pages={69--76},
  year={2020},
  publisher={Springer}
}

@article{howard1993intelligence,
  title={On what intelligence is},
  author={Howard, Robert W},
  journal={British Journal of Psychology},
  volume={84},
  number={1},
  pages={27--37},
  year={1993},
  publisher={Wiley Online Library}
}

@article{wang2019defining,
  title={On defining artificial intelligence},
  author={Wang, Pei},
  journal={Journal of Artificial General Intelligence},
  volume={10},
  number={2},
  pages={1--37},
  year={2019},
  publisher={De Gruyter Poland}
}

@article{thiele2022multitask,
  title={Multitask brain network reconfiguration is inversely associated with human intelligence},
  author={Thiele, Jonas A and Faskowitz, Joshua and Sporns, Olaf and Hilger, Kirsten},
  journal={Cerebral Cortex},
  volume={32},
  number={19},
  pages={4172--4182},
  year={2022},
  publisher={Oxford University Press}
}

@article{sternberg2004culture,
  title={Culture and intelligence.},
  author={Sternberg, Robert J},
  journal={American psychologist},
  volume={59},
  number={5},
  pages={325},
  year={2004},
  publisher={American Psychological Association}
}

@article{kan2013nature,
  title={On the nature and nurture of intelligence and specific cognitive abilities: The more heritable, the more culture dependent},
  author={Kan, Kees-Jan and Wicherts, Jelte M and Dolan, Conor V and van der Maas, Han LJ},
  journal={Psychological science},
  volume={24},
  number={12},
  pages={2420--2428},
  year={2013},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@book{clark1998being,
  title={Being there: Putting brain, body, and world together again},
  author={Clark, Andy},
  year={1998},
  publisher={MIT press}
}

@article{brooks1991intelligence,
  title={Intelligence without representation},
  author={Brooks, Rodney A},
  journal={Artificial intelligence},
  volume={47},
  number={1-3},
  pages={139--159},
  year={1991},
  publisher={Elsevier}
}

@book{varela2017embodied,
  title={The embodied mind, revised edition: Cognitive science and human experience},
  author={Varela, Francisco J and Thompson, Evan and Rosch, Eleanor},
  year={2017},
  publisher={MIT press}
}

@article{jin2020embodied,
  title={Embodied intelligence weaves a better future},
  author={Jin, Dongdong and Zhang, Li},
  journal={Nature Machine Intelligence},
  volume={2},
  number={11},
  pages={663--664},
  year={2020},
  publisher={Nature Publishing Group UK London}
}

@book{siegler1998emerging,
  title={Emerging minds: The process of change in children's thinking},
  author={Siegler, Robert S},
  year={1998},
  publisher={Oxford University Press}
}

@inproceedings{chiang2024chatbot,
title={Chatbot Arena: An Open Platform for Evaluating {LLM}s by Human Preference},
author={Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Banghua Zhu and Hao Zhang and Michael Jordan and Joseph E. Gonzalez and Ion Stoica},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
url={https://openreview.net/forum?id=3MW8GKNyzI}
}

@article{aj2023holistic,
  title={A Holistic Test for (Artificial) General Intelligence},
  author={AJ, Gomez-Ramirez Danny and Judith, Kieninger},
  year={2023}
}

@inproceedings{10.5555/3666122.3669277,
author = {Huang, Shaohan and Dong, Li and Wang, Wenhui and Hao, Yaru and Singhal, Saksham and Ma, Shuming and Lv, Tengchao and Cui, Lei and Mohammed, Owais Khan and Patra, Barun and Liu, Qiang and Aggarwal, Kriti and Chi, Zewen and Bjorck, Johan and Chaudhary, Vishrav and Som, Subhojit and Song, Xia and Wei, Furu},
title = {Language is not all you need: aligning perception with language models},
year = {2023},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {A big convergence of language, multimodal perception, action, and world modeling is a key step toward artificial general intelligence. In this work, we introduce KOSMOS-1, a Multimodal Large Language Model (MLLM) that can perceive general modalities, learn in context (i.e., few-shot), and follow instructions (i.e., zero-shot). Specifically, we train KOSMOS-1 from scratch on web-scale multimodal corpora, including arbitrarily interleaved text and images, image-caption pairs, and text data. We evaluate various settings, including zero-shot, few-shot, and multimodal chain-of-thought prompting, on a wide range of tasks without any gradient updates or finetuning. Experimental results show that KOSMOS-1 achieves impressive performance on (i) language understanding, generation, and even OCR-free NLP (directly fed with document images), (ii) perception-language tasks, including multimodal dialogue, image captioning, visual question answering, and (iii) vision tasks, such as image recognition with descriptions (specifying classification via text instructions). We also show that MLLMs can benefit from cross-modal transfer, i.e., transfer knowledge from language to multimodal, and from multimodal to language. In addition, we introduce a dataset of Raven IQ test, which diagnoses the nonverbal reasoning capability of MLLMs.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {3155},
numpages = {14},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}
@incollection{Serpico2018-SERCTG,
	author = {Davide Serpico and Marcello Frixione},
	booktitle = {Proceedings of the Society for the Study of Artificial Intelligence and Simulation of Behaviour 2018},
	editor = {Davide Serpico and Marcello Frixione},
	pages = {301--305},
	title = {Can the G Factor Play a Role in Artificial General Intelligence Research?},
	year = {2018}
}

@misc{chollet2019measureintelligence,
      title={On the Measure of Intelligence}, 
      author={François Chollet},
      year={2019},
      eprint={1911.01547},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/1911.01547}, 
}
@inproceedings{merlo-2023-blackbird,
    title = "Blackbird language matrices ({BLM}), a new task for rule-like generalization in neural networks: Can Large Language Models pass the test?",
    author = "Merlo, Paola",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2023",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-emnlp.546/",
    doi = "10.18653/v1/2023.findings-emnlp.546",
    pages = "8119--8152",
    abstract = "How do we evaluate Large Language Models (LLMs) and determine the aspects and limits of their intelligent behaviour? It is currently conjectured that shortcomings of LLMs in multi-linguality and reasoning are due to a lack of ability to generalize. It has been argued that, instead, humans are better at generalization because they have a tendency at extracting rules from complex data. We propose a method to evaluate LLMs ability to rule-based generalization. When exposed to tests of analytic intelligence, for example the visual RAVEN IQ test, human problem-solvers identify the relevant objects in the picture and their relevant attributes and reason based on rules applied to them. Based on the induced rules, they are able to provide a generalisation and a solution to the test. An analogous language task has recently been proposed (called BLM) for LLM. In this paper, we argue that we can use this task to investigate what linguistic reasoning LLM develop, by asking them to solve some simple variants of the BLM task. We find that current state-of-the-art generative models, such as ChatGPT, can handle the task in the sense that they easily understand the instructions and can provide step-by-step reasoning that shows that it can solve two of the main cognitive hurdles: correspondence finding (object and attribute identification) and item novelty. However, overall they cannot find the correct answer, even with considerable help. In particular, they never identify the structure of the problem, exhibiting, we hypothesize, a lack of goal and subgoal management abilities, an ability that has been argued to measure differential abilities in humans. We argue that this finding supports the usefulness of the task as a method to test the limits and specific properties of generalisation ability in Large Language Models, providing an intrinsic evaluation method inspired by tests of human intelligence."
}
@misc{barrett2018measuringabstractreasoningneural,
      title={Measuring abstract reasoning in neural networks}, 
      author={David G. T. Barrett and Felix Hill and Adam Santoro and Ari S. Morcos and Timothy Lillicrap},
      year={2018},
      eprint={1807.04225},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1807.04225}, 
}
@inproceedings{
huang2023language,
title={Language Is Not All You Need: Aligning Perception with Language Models},
author={Shaohan Huang and Li Dong and Wenhui Wang and Yaru Hao and Saksham Singhal and Shuming Ma and Tengchao Lv and Lei Cui and Owais Khan Mohammed and Barun Patra and Qiang Liu and Kriti Aggarwal and Zewen Chi and Johan Bjorck and Vishrav Chaudhary and Subhojit Som and Xia Song and Furu Wei},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
year={2023},
url={https://openreview.net/forum?id=UpN2wfrLec}
}
@article{lake2017building,
  title={Building machines that learn and think like people},
  author={Lake, Brenden M and Ullman, Tomer D and Tenenbaum, Joshua B and Gershman, Samuel J},
  journal={Behavioral and brain sciences},
  volume={40},
  pages={e253},
  year={2017},
  publisher={Cambridge University Press}
}

@article{bowman2021will,
  title={What will it take to fix benchmarking in natural language understanding?},
  author={Bowman, Samuel R and Dahl, George E},
  journal={arXiv preprint arXiv:2104.02145},
  year={2021}
}

@inproceedings{10.5555/3042573.3042809,
author = {Wagstaff, Kiri L.},
title = {Machine learning that matters},
year = {2012},
isbn = {9781450312851},
publisher = {Omnipress},
address = {Madison, WI, USA},
abstract = {Much of current machine learning (ML) research has lost its connection to problems of import to the larger world of science and society. From this perspective, there exist glaring limitations in the data sets we investigate, the metrics we employ for evaluation, and the degree to which results are communicated back to their originating domains. What changes are needed to how we conduct research to increase the impact that ML has? We present six Impact Challenges to explicitly focus the field's energy and attention, and we discuss existing obstacles that must be addressed. We aim to inspire ongoing discussion and focus on ML that matters.},
booktitle = {Proceedings of the 29th International Coference on International Conference on Machine Learning},
pages = {1851–1856},
numpages = {6},
location = {Edinburgh, Scotland},
series = {ICML'12}
}

@inproceedings{akyurek-etal-2022-challenges,
    title = "Challenges in Measuring Bias via Open-Ended Language Generation",
    author = {Aky{\"u}rek, Afra Feyza  and
      Kocyigit, Muhammed Yusuf  and
      Paik, Sejin  and
      Wijaya, Derry Tanti},
    editor = "Hardmeier, Christian  and
      Basta, Christine  and
      Costa-juss{\`a}, Marta R.  and
      Stanovsky, Gabriel  and
      Gonen, Hila",
    booktitle = "Proceedings of the 4th Workshop on Gender Bias in Natural Language Processing (GeBNLP)",
    month = jul,
    year = "2022",
    address = "Seattle, Washington",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.gebnlp-1.9/",
    doi = "10.18653/v1/2022.gebnlp-1.9",
    pages = "76--76",
    abstract = "Researchers have devised numerous ways to quantify social biases vested in pretrained language models. As some language models are capable of generating coherent completions given a set of textual prompts, several prompting datasets have been proposed to measure biases between social groups{---}posing language generation as a way of identifying biases. In this opinion paper, we analyze how specific choices of prompt sets, metrics, automatic tools and sampling strategies affect bias results. We find out that the practice of measuring biases through text completion is prone to yielding contradicting results under different experiment settings. We additionally provide recommendations for reporting biases in open-ended language generation for a more complete outlook of biases exhibited by a given language model. Code to reproduce the results is released under \url{https://github.com/feyzaakyurek/bias-textgen}."
}

@inproceedings{blodgett-etal-2021-stereotyping,
    title = "Stereotyping {N}orwegian Salmon: An Inventory of Pitfalls in Fairness Benchmark Datasets",
    author = "Blodgett, Su Lin  and
      Lopez, Gilsinia  and
      Olteanu, Alexandra  and
      Sim, Robert  and
      Wallach, Hanna",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.81/",
    doi = "10.18653/v1/2021.acl-long.81",
    pages = "1004--1015",
    abstract = "Auditing NLP systems for computational harms like surfacing stereotypes is an elusive goal. Several recent efforts have focused on benchmark datasets consisting of pairs of contrastive sentences, which are often accompanied by metrics that aggregate an NLP system`s behavior on these pairs into measurements of harms. We examine four such benchmarks constructed for two NLP tasks: language modeling and coreference resolution. We apply a measurement modeling lens{---}originating from the social sciences{---}to inventory a range of pitfalls that threaten these benchmarks' validity as measurement models for stereotyping. We find that these benchmarks frequently lack clear articulations of what is being measured, and we highlight a range of ambiguities and unstated assumptions that affect how these benchmarks conceptualize and operationalize stereotyping."
}

@article{shui2019principled,
  title={A principled approach for learning task similarity in multitask learning},
  author={Shui, Changjian and Abbasi, Mahdieh and Robitaille, Louis-{\'E}mile and Wang, Boyu and Gagn{\'e}, Christian},
  journal={arXiv preprint arXiv:1903.09109},
  year={2019}
}

@inproceedings{blodgett-etal-2024-human,
    title = "Human-Centered Evaluation of Language Technologies",
    author = "Blodgett, Su Lin  and
      Cheung, Jackie Chi Kit  and
      Liao, Vera  and
      Xiao, Ziang",
    editor = "Li, Jessy  and
      Liu, Fei",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts",
    month = nov,
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-tutorials.6/",
    doi = "10.18653/v1/2024.emnlp-tutorials.6",
    pages = "39--43",
    abstract = "Evaluation is a cornerstone topic in NLP. However, many criticisms have been raised about the community`s evaluation practices, including a lack of human-centered considerations about people`s needs for language technologies and their actual impact on people. This {\textquotedblleft}evaluation crisis{\textquotedblright} is exacerbated by the recent development of large generative models with diverse and uncertain capabilities. This tutorial aims to inspire more human-centered evaluation in NLP by introducing perspectives and methodologies from human-computer interaction (HCI), a field concerned primarily with the design and evaluation of technologies. The tutorial will start with an overview of current NLP evaluation practices and their limitations, then introduce the {\textquotedblleft}toolbox of evaluation methods{\textquotedblright} from HCI with varying considerations such as what to evaluate for, how generalizable the results are to the real-world contexts, and pragmatic costs to conduct the evaluation. The tutorial will also encourage reflection on how these HCI perspectives and methodologies can complement NLP evaluation through Q{\&}A discussions and a hands-on exercise."
}



@article{tenenbaum2001generalization,
  title={Generalization, similarity, and Bayesian inference},
  author={Tenenbaum, Joshua B and Griffiths, Thomas L},
  journal={Behavioral and brain sciences},
  volume={24},
  number={4},
  pages={629--640},
  year={2001},
  publisher={Cambridge University Press}
}

@article{liu2024ecbd,
  title={ECBD: Evidence-centered benchmark design for NLP},
  author={Liu, Yu Lu and Blodgett, Su Lin and Cheung, Jackie Chi Kit and Liao, Q Vera and Olteanu, Alexandra and Xiao, Ziang},
  journal={arXiv preprint arXiv:2406.08723},
  year={2024}
}

@article{tomov2021multi,
  title={Multi-task reinforcement learning in humans},
  author={Tomov, Momchil S and Schulz, Eric and Gershman, Samuel J},
  journal={Nature Human Behaviour},
  volume={5},
  number={6},
  pages={764--773},
  year={2021},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{guan2022task,
    title={Task Relatedness-Based Generalization Bounds for Meta Learning},
    author={Jiechao Guan and Zhiwu Lu},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=A3HHaEdqAJL}
}

@book{minsky1988society,
  title={Society of mind},
  author={Minsky, Marvin},
  year={1988},
  publisher={Simon and Schuster}
}

@incollection{sims2013theory,
  title={The theory and philosophy of intelligence},
  author={Sims, Jennifer},
  booktitle={Routledge companion to intelligence studies},
  pages={42--49},
  year={2013},
  publisher={Routledge}
}

@book{wittgenstein1958blue,
  title={The blue and brown books},
  author={Wittgenstein, Ludwig},
  volume={18},
  year={1958},
  publisher={Blackwell Oxford}
}

@article{sternberg1977triarchic,
  title={Triarchic theory},
  author={Sternberg, Robert},
  journal={Intelligence, Information Processing, and Analogical Reasoning},
  year={1977},
  publisher={Erlbaum Hillside, NJ}
}

@article{sternberg2015successful,
  title={Successful intelligence: A model for testing intelligence beyond IQ tests},
  author={Sternberg, Robert J},
  journal={European Journal of Education and Psychology},
  volume={8},
  number={2},
  pages={76--84},
  year={2015},
  publisher={Elsevier}
}

@article{tenenbaum2001generalization,
  title={Generalization, similarity, and Bayesian inference},
  author={Tenenbaum, Joshua B and Griffiths, Thomas L},
  journal={Behavioral and brain sciences},
  volume={24},
  number={4},
  pages={629--640},
  year={2001},
  publisher={Cambridge University Press}
}

@article{gardner1987theory,
  title={The theory of multiple intelligences},
  author={Gardner, Howard},
  journal={Annals of dyslexia},
  pages={19--35},
  year={1987},
  publisher={JSTOR}
}

@article{shah2024stackeval,
  title={StackEval: Benchmarking LLMs in Coding Assistance},
  author={Shah, Nidhish and Genc, Zulkuf and Araci, Dogu},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={36976--36994},
  year={2024}
}

@article{young1999soar,
  title={The Soar cognitive architecture and human working memory},
  author={Young, Richard M and Lewis, Richard L},
  journal={Models of working memory: Mechanisms of active maintenance and executive control},
  pages={224--256},
  year={1999},
  publisher={Citeseer}
}

@article{ritter2019act,
  title={ACT-R: A cognitive architecture for modeling cognition},
  author={Ritter, Frank E and Tehranchi, Farnaz and Oury, Jacob D},
  journal={Wiley Interdisciplinary Reviews: Cognitive Science},
  volume={10},
  number={3},
  pages={e1488},
  year={2019},
  publisher={Wiley Online Library}
}

@article{phan2025humanity,
  title={Humanity's Last Exam},
  author={Phan, Long and Gatti, Alice and Han, Ziwen and Li, Nathaniel and Hu, Josephina and Zhang, Hugh and Zhang, Chen Bo Calvin and Shaaban, Mohamed and Ling, John and Shi, Sean and others},
  journal={arXiv preprint arXiv:2501.14249},
  year={2025}
}

@book{shalev2014understanding,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@article{horn1968organization,
  title={Organization of abilities and the development of intelligence.},
  author={Horn, John L},
  journal={Psychological review},
  volume={75},
  number={3},
  pages={242},
  year={1968},
  publisher={American Psychological Association}
}

@inproceedings{rein2024gpqa,
  title={Gpqa: A graduate-level google-proof q\&a benchmark},
  author={Rein, David and Hou, Betty Li and Stickland, Asa Cooper and Petty, Jackson and Pang, Richard Yuanzhe and Dirani, Julien and Michael, Julian and Bowman, Samuel R},
  booktitle={First Conference on Language Modeling},
  year={2024}
}

@incollection{simon2024identifying,
  title={Identifying basic abilities underlying intelligent performance of complex tasks},
  author={Simon, Herbert A},
  booktitle={The nature of intelligence},
  pages={65--98},
  year={2024},
  publisher={Routledge}
}

@inproceedings{ben2003exploiting,
  title={Exploiting task relatedness for multiple task learning},
  author={Ben-David, Shai and Schuller, Reba},
  booktitle={Learning Theory and Kernel Machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, USA, August 24-27, 2003. Proceedings},
  pages={567--580},
  year={2003},
  organization={Springer}
}

@article{kazemi2025big,
  title={BIG-Bench Extra Hard},
  author={Kazemi, Mehran and Fatemi, Bahare and Bansal, Hritik and Palowitch, John and Anastasiou, Chrysovalantis and Mehta, Sanket Vaibhav and Jain, Lalit K and Aglietti, Virginia and Jindal, Disha and Chen, Peter and others},
  journal={arXiv preprint arXiv:2502.19187},
  year={2025}
}

@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}

@article{davis2023benchmarks,
  title={Benchmarks for automated commonsense reasoning: A survey},
  author={Davis, Ernest},
  journal={ACM Computing Surveys},
  volume={56},
  number={4},
  pages={1--41},
  year={2023},
  publisher={ACM New York, NY, USA}
}

@article{cobbe2021training,
  title={Training verifiers to solve math word problems},
  author={Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and others},
  journal={arXiv preprint arXiv:2110.14168},
  year={2021}
}

@book{nash1990intelligence,
  title={Intelligence and realism: A materialist critique of IQ},
  author={Nash, Roy},
  year={1990},
  publisher={Springer}
}

@book{bolter1984turing,
  title={Turing's man: Western culture in the computer age},
  author={Bolter, J David},
  year={1984},
  publisher={UNC Press Books}
}

@article{fjelland2020general,
  title={Why general artificial intelligence will not be realized},
  author={Fjelland, Ragnar},
  journal={Humanities and Social Sciences Communications},
  volume={7},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Palgrave}
}

@inproceedings{ijcai2019p0478,
  title     = {A Principled Approach for Learning Task Similarity in Multitask Learning},
  author    = {Shui, Changjian and Abbasi, Mahdieh and Robitaille, Louis-Émile and Wang, Boyu and Gagné, Christian},
  booktitle = {Proceedings of the Twenty-Eighth International Joint Conference on
               Artificial Intelligence, {IJCAI-19}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  pages     = {3446--3452},
  year      = {2019},
  month     = {7},
  doi       = {10.24963/ijcai.2019/478},
  url       = {https://doi.org/10.24963/ijcai.2019/478},
}

@inproceedings{raji2021ai,
title={{AI} and the Everything in the Whole Wide World Benchmark},
author={Inioluwa Deborah Raji and Emily Denton and Emily M. Bender and Alex Hanna and Amandalynne Paullada},
booktitle={Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)},
year={2021},
url={https://openreview.net/forum?id=j6NxpQbREA1}
}

@book{summerfield2023natural,
  title={Natural General Intelligence: How understanding the brain can help us build AI},
  author={Summerfield, Christopher},
  year={2023},
  publisher={Oxford university press}
}

@inproceedings{blili2024unsocial,
  title={Unsocial Intelligence: An Investigation of the Assumptions of AGI Discourse},
  author={Blili-Hamelin, Borhane and Hancox-Li, Leif and Smart, Andrew},
  booktitle={Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
  volume={7},
  pages={141--155},
  year={2024}
}

@article{mueller2024myth,
  title={The Myth of AGI},
  author={Mueller, Milton},
  journal={Internet Governance Project},
  year={2024}

}

@inproceedings{10.5555/3692070.3692121,
  author = {Altmeyer, Patrick and Demetriou, Andrew M. and Bartlett, Antony and Liem, Cynthia C. S.},
  title = {Position: stop making unscientific AGI performance claims},
  year = {2024},
  publisher = {JMLR.org},
  abstract = {Developments in the field of Artificial Intelligence (AI), and particularly large language models (LLMs), have created a 'perfect storm' for observing 'sparks' of Artificial General Intelligence (AGI) that are spurious. Like simpler models, LLMs distill meaningful representations in their latent embeddings that have been shown to correlate with external variables. Nonetheless, the correlation of such representations has often been linked to human-like intelligence in the latter but not the former. We probe models of varying complexity including random projections, matrix decompositions, deep autoencoders and transformers: all of them successfully distill information that can be used to predict latent or external variables and yet none of them have previously been linked to AGI. We argue and empirically demonstrate that the finding of meaningful patterns in latent spaces of models cannot be seen as evidence in favor of AGI. Additionally, we review literature from the social sciences that shows that humans are prone to seek such patterns and anthropomorphize. We conclude that both the methodological setup and common public image of AI are ideal for the misinterpretation that correlations between model representations and some variables of interest are 'caused' by the model's understanding of underlying 'ground truth' relationships. We, therefore, call for the academic community to exercise extra caution, and to be keenly aware of principles of academic integrity, in interpreting and communicating about AI research outcomes.},
  booktitle = {Proceedings of the 41st International Conference on Machine Learning},
  articleno = {51},
  numpages = {21},
  location = {Vienna, Austria},
  series = {ICML'24}
  }


@article{blili2025stop,
  title={Stop treatingAGI'as the north-star goal of AI research},
  author={Blili-Hamelin, Borhane and Graziul, Christopher and Hancox-Li, Leif and Hazan, Hananel and El-Mhamdi, El-Mahdi and Ghosh, Avijit and Heller, Katherine and Metcalf, Jacob and Murai, Fabricio and Salvaggio, Eryk and others},
  journal={arXiv preprint arXiv:2502.03689},
  year={2025}
}

@article{henrich2010weirdest,
  title={The weirdest people in the world?},
  author={Henrich, Joseph and Heine, Steven J and Norenzayan, Ara},
  journal={Behavioral and brain sciences},
  volume={33},
  number={2-3},
  pages={61--83},
  year={2010},
  publisher={Cambridge University Press}
}



@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on robot learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@incollection{thrun1998learning,
  title={Learning to learn: Introduction and overview},
  author={Thrun, Sebastian and Pratt, Lorien},
  booktitle={Learning to learn},
  pages={3--17},
  year={1998},
  publisher={Springer}
}

@article{maurer2006bounds,
  title={Bounds for linear multi-task learning},
  author={Maurer, Andreas},
  journal={The Journal of Machine Learning Research},
  volume={7},
  pages={117--139},
  year={2006},
  publisher={JMLR. org}
}

@article{baxter2000model,
  title={A model of inductive bias learning},
  author={Baxter, Jonathan},
  journal={Journal of artificial intelligence research},
  volume={12},
  pages={149--198},
  year={2000}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{caruana1993multitask,
  title={Multitask learning: A knowledge-based source of inductive bias1},
  author={Caruana, R},
  booktitle={Proceedings of the Tenth International Conference on Machine Learning},
  pages={41--48},
  year={1993},
  organization={Citeseer}
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{turing1950mind,
  title={Mind},
  author={Turing, Alan Mathison},
  journal={Mind},
  volume={59},
  number={236},
  pages={433--460},
  year={1950}
}

@book{minsky1956heuristic,
  title={Heuristic aspects of the artificial intelligence problem},
  author={Minsky, Marvin},
  year={1956},
  publisher={Ed. Services Technical Information agency:[Springfield, Va.]: distiributed~…}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}

@article{ilic2024evidence,
  title={Evidence of interrelated cognitive-like capabilities in large language models: Indications of artificial general intelligence or achievement?},
  author={Ili{\'c}, David and Gignac, Gilles E},
  journal={Intelligence},
  volume={106},
  pages={101858},
  year={2024},
  publisher={Elsevier}
}

@article{croitoru2023diffusion,
  title={Diffusion models in vision: A survey},
  author={Croitoru, Florinel-Alin and Hondru, Vlad and Ionescu, Radu Tudor and Shah, Mubarak},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={9},
  pages={10850--10869},
  year={2023},
  publisher={IEEE}
}

@inproceedings{kenton2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Kenton, Jacob Devlin Ming-Wei Chang and Toutanova, Lee Kristina},
  booktitle={Proceedings of naacL-HLT},
  volume={1},
  pages={2},
  year={2019},
  organization={Minneapolis, Minnesota}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{bubeck2023sparks,
  title={Sparks of artificial general intelligence: Early experiments with gpt-4},
  author={Bubeck, S{\'e}bastien and Chandrasekaran, Varun and Eldan, Ronen and Gehrke, Johannes and Horvitz, Eric and Kamar, Ece and Lee, Peter and Lee, Yin Tat and Li, Yuanzhi and Lundberg, Scott and others},
  journal={arXiv preprint arXiv:2303.12712},
  year={2023}
}

@article{zhong2024evaluation,
  title={Evaluation of openai o1: Opportunities and challenges of agi},
  author={Zhong, Tianyang and Liu, Zhengliang and Pan, Yi and Zhang, Yutong and Zhou, Yifan and Liang, Shizhe and Wu, Zihao and Lyu, Yanjun and Shu, Peng and Yu, Xiaowei and others},
  journal={arXiv preprint arXiv:2409.18486},
  year={2024}
}

@book{mercier2017enigma,
  title={The enigma of reason},
  author={Mercier, Hugo and Sperber, Dan},
  year={2017},
  publisher={Harvard University Press}
}

@article{holm2024intelligence,
  title={Intelligence in animals, humans and machines: a heliocentric view of intelligence?},
  author={Holm, Halfdan and Banerjee, Soumya},
  journal={AI \& SOCIETY},
  pages={1--3},
  year={2024},
  publisher={Springer}
}

@misc{churchland1984matter,
  title={Matter and Consciousness: A Contemporary Introduction},
  author={Churchland, Paul M},
  year={1984},
  publisher={Cambridge, MA: MIT Press}
}

@article{ryle1949descartes,
  title={Descartes’ myth},
  author={Ryle, Gilbert},
  journal={The concept of mind},
  pages={11--24},
  year={1949},
  publisher={University of Oxford}
}

@article{legg2007collection,
  title={A collection of definitions of intelligence},
  author={Legg, Shane and Hutter, Marcus and others},
  journal={Frontiers in Artificial Intelligence and applications},
  volume={157},
  pages={17},
  year={2007},
  publisher={IOS press}
}

@book{russell2016artificial,
  title={Artificial intelligence: a modern approach},
  author={Russell, Stuart J and Norvig, Peter},
  year={2016},
  publisher={Pearson}
}

@article{penny1995embodied,
  title={Embodied Mind: Cognitive Science and Human Experience by Francisco J. Varela, Evan Thompson, Eleanor Rosch},
  author={Penny, Simon},
  journal={Leonardo},
  volume={28},
  number={4},
  pages={337--338},
  year={1995},
  publisher={The MIT Press}
}

@article{cangelosi2015embodied,
  title={Embodied intelligence},
  author={Cangelosi, Angelo and Bongard, Josh and Fischer, Martin H and Nolfi, Stefano},
  journal={Springer handbook of computational intelligence},
  pages={697--714},
  year={2015},
  publisher={Springer}
}

@book{hutter2005universal,
  title={Universal artificial intelligence: Sequential decisions based on algorithmic probability},
  author={Hutter, Marcus},
  year={2005},
  publisher={Springer Science \& Business Media}
}

@article{legg2007collection,
  title={A collection of definitions of intelligence},
  author={Legg, Shane and Hutter, Marcus and others},
  journal={Frontiers in Artificial Intelligence and applications},
  volume={157},
  pages={17},
  year={2007},
  publisher={IOS press}
}

@incollection{sims2013theory,
  title={The theory and philosophy of intelligence},
  author={Sims, Jennifer},
  booktitle={Routledge companion to intelligence studies},
  pages={42--49},
  year={2013},
  publisher={Routledge}
}

@book{sternberg1990metaphors,
  title={Metaphors of mind: Conceptions of the nature of intelligence},
  author={Sternberg, Robert J},
  year={1990},
  publisher={Cambridge University Press}
}

@book{sternberg2005cognition,
  title={Cognition and intelligence: Identifying the mechanisms of the mind.},
  author={Sternberg, Robert J and Pretz, Jean E},
  year={2005},
  publisher={Cambridge University Press}
}

@book{pfeifer2001understanding,
  title={Understanding intelligence},
  author={Pfeifer, Rolf and Scheier, Christian},
  year={2001},
  publisher={MIT press}
}

@article{demetriou20051,
  title={1 Mind, Mind, intelligence and development: a cognitive, differential and developmental theory of intelligence},
  author={Demetriou, Andreas},
  journal={Cognitive developmental change: Theories, models and measurement},
  volume={10},
  pages={21},
  year={2005},
  publisher={Cambridge University Press}
}

@article{ritchie2018much,
  title={How much does education improve intelligence? A meta-analysis},
  author={Ritchie, Stuart J and Tucker-Drob, Elliot M},
  journal={Psychological science},
  volume={29},
  number={8},
  pages={1358--1369},
  year={2018},
  publisher={Sage Publications Sage CA: Los Angeles, CA}
}

@book{poole2010artificial,
  title={Artificial Intelligence: foundations of computational agents},
  author={Poole, David L and Mackworth, Alan K},
  year={2010},
  publisher={Cambridge University Press}
}

@article{kaplan2019siri,
  title={Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence},
  author={Kaplan, Andreas and Haenlein, Michael},
  journal={Business horizons},
  volume={62},
  number={1},
  pages={15--25},
  year={2019},
  publisher={Elsevier}
}

@Inbook{Bartneck2021,
    author="Bartneck, Christoph
    and L{\"u}tge, Christoph
    and Wagner, Alan
    and Welsh, Sean",
    title="What Is AI?",
    bookTitle="An Introduction to Ethics in Robotics and AI",
    year="2021",
    publisher="Springer International Publishing",
    address="Cham",
    pages="5--16",
    abstract="In this chapter we discuss the different definitions of Artificial Intelligence (AI). We then discuss how machines learn and how a robot works in general. Finally we discuss the limitations of AI and the influence the media has on our preconceptions of AI.",
    isbn="978-3-030-51110-4",
    doi="10.1007/978-3-030-51110-4_2",
    url="https://doi.org/10.1007/978-3-030-51110-4_2"
}

@article{andreasen1993intelligence,
  title={Intelligence and brain structure in normal individuals},
  author={Andreasen, Nancy C and Flaum, Michael and Swayze, Victor and O'Leary, Daniel S and Alliger, Randall and Cohen, Gregg and Ehrhardt, James and Yuh, William T and others},
  journal={American Journal of Psychiatry},
  volume={150},
  pages={130--130},
  year={1993},
  publisher={American Psychiatric Association}
}

@article{wickett2000relationships,
  title={Relationships between factors of intelligence and brain volume},
  author={Wickett, John C and Vernon, Philip A and Lee, Donald H},
  journal={Personality and individual differences},
  volume={29},
  number={6},
  pages={1095--1122},
  year={2000},
  publisher={Elsevier}
}

@article{egan1994size,
  title={Size isn't everything: A study of brain volume, intelligence and auditory evoked potentials},
  author={Egan, Vincent and Chiswick, Ann and Santosh, Celestine and Naidu, K and Rimmington, J Ewen and Best, Jonathan JK},
  journal={Personality and Individual Differences},
  volume={17},
  number={3},
  pages={357--367},
  year={1994},
  publisher={Elsevier}
}

@article{pietschnig2015meta,
  title={Meta-analysis of associations between human brain volume and intelligence differences: How strong are they and what do they mean?},
  author={Pietschnig, Jakob and Penke, Lars and Wicherts, Jelte M and Zeiler, Michael and Voracek, Martin},
  journal={Neuroscience \& Biobehavioral Reviews},
  volume={57},
  pages={411--432},
  year={2015},
  publisher={Elsevier}
}

@article{gignac2017brain,
  title={Brain volume and intelligence: The moderating role of intelligence measurement quality},
  author={Gignac, Gilles E and Bates, Timothy C},
  journal={Intelligence},
  volume={64},
  pages={18--29},
  year={2017},
  publisher={Elsevier}
}

@article{mackintosh1986biology,
  title={The biology of intelligence?},
  author={Mackintosh, NJ},
  journal={British journal of psychology},
  volume={77},
  number={1},
  pages={1--18},
  year={1986},
  publisher={Wiley Online Library}
}

@article{sternberg2003biological,
  title={Biological intelligence},
  author={Sternberg, Robert J},
  journal={The psychology of abilities, competencies, and expertise},
  pages={240--262},
  year={2003}
}

@article{colom2010human,
  title={Human intelligence and brain networks},
  author={Colom, Roberto and Karama, Sherif and Jung, Rex E and Haier, Richard J},
  journal={Dialogues in clinical neuroscience},
  volume={12},
  number={4},
  pages={489--501},
  year={2010},
  publisher={Taylor \& Francis}
}

@book{terman1916measurement,
  title={The measurement of intelligence},
  author={Terman, Lewis Madison},
  volume={191},
  year={1916},
  publisher={Houghton Mifflin Company Boston}
}

@article{binet1948development,
  title={The development of the Binet-Simon Scale, 1905-1908.},
  author={Binet, Alfred and Simon, Theophile},
  year={1948},
  publisher={Appleton-Century-Crofts}
}

@book{wechsler1949wechsler,
  title={Wechsler intelligence scale for children},
  author={Wechsler, David and Kodama, Habuku},
  volume={1},
  year={1949},
  publisher={Psychological corporation New York}
}

@article{schonemann1983iq,
  title={Do IQ tests really measure intelligence?},
  author={Sch{\"o}nemann, Peter H},
  journal={Behavioral and Brain Sciences},
  volume={6},
  number={2},
  pages={311--313},
  year={1983},
  publisher={Cambridge University Press}
}

@article{detterman1989correlations,
  title={Correlations of mental tests with each other and with cognitive variables are highest for low IQ groups},
  author={Detterman, Douglas K and Daniel, Mark H},
  journal={Intelligence},
  volume={13},
  number={4},
  pages={349--359},
  year={1989},
  publisher={Elsevier}
}

@book{stanovich2009intelligence,
  title={What intelligence tests miss: The psychology of rational thought},
  author={Stanovich, Keith E},
  year={2009},
  publisher={Yale University Press}
}

@article{flynn1999searching,
  title={Searching for justice: the discovery of IQ gains over time.},
  author={Flynn, James R},
  journal={American psychologist},
  volume={54},
  number={1},
  pages={5},
  year={1999},
  publisher={American Psychological Association}
}

@book{raven1989standard,
  title={Standard progressive matrices},
  author={Raven, John C and John Hugh Court and Raven, John Earle},
  year={1989},
  publisher={Australian Council for Educational Research Limited Camberwell, Australia}
}

@misc{gould1996mismeasure,
  title={The mismeasure of man},
  author={Gould, Stephen Jay},
  year={1996},
  publisher={Norton}
}

@book{moor2003turing,
  title={The Turing test: the elusive standard of artificial intelligence},
  author={Moor, James},
  volume={30},
  year={2003},
  publisher={Springer Science \& Business Media}
}

@article{hoffmann2022ai,
  title={Is AI intelligent? An assessment of artificial intelligence, 70 years after Turing},
  author={Hoffmann, Christian Hugo},
  journal={Technology in Society},
  volume={68},
  pages={101893},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{altmeyerposition,
  title={Position: Stop Making Unscientific AGI Performance Claims},
  author={Altmeyer, Patrick and Demetriou, Andrew M and Bartlett, Antony and Liem, Cynthia CS},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{mclean2023risks,
  title={The risks associated with Artificial General Intelligence: A systematic review},
  author={McLean, Scott and Read, Gemma JM and Thompson, Jason and Baber, Chris and Stanton, Neville A and Salmon, Paul M},
  journal={Journal of Experimental \& Theoretical Artificial Intelligence},
  volume={35},
  number={5},
  pages={649--663},
  year={2023},
  publisher={Taylor \& Francis}
}

@incollection{mahler2022regulating,
  title={Regulating artificial general intelligence (AGI)},
  author={Mahler, Tobias},
  booktitle={Law and artificial intelligence: Regulating AI and applying AI in legal practice},
  pages={521--540},
  year={2022},
  publisher={Springer}
}

@article{dou2023towards,
  title={Towards artificial general intelligence (agi) in the internet of things (iot): Opportunities and challenges},
  author={Dou, Fei and Ye, Jin and Yuan, Geng and Lu, Qin and Niu, Wei and Sun, Haijian and Guan, Le and Lu, Guoyu and Mai, Gengchen and Liu, Ninghao and others},
  journal={arXiv preprint arXiv:2309.07438},
  year={2023}
}

@inproceedings{gubrud1997nanotechnology,
  title={Nanotechnology and international security},
  author={Gubrud, Mark Avrum},
  booktitle={Fifth Foresight Conference on Molecular Nanotechnology},
  volume={1},
  year={1997}
}

@article{hutter2000theory,
  title={A theory of universal artificial intelligence based on algorithmic complexity},
  author={Hutter, Marcus},
  journal={arXiv preprint cs/0004001},
  year={2000}
}

@inproceedings{edmonds2012learning,
  title={Learning, Social Intelligence and the Turing Test: Why an “Out-of-the-Box” Turing Machine Will Not Pass the Turing Test},
  author={Edmonds, Bruce and Gershenson, Carlos},
  booktitle={Conference on Computability in Europe},
  pages={182--192},
  year={2012},
  organization={Springer}
}

@article{landgrebe2019there,
  title={There is no artificial general intelligence},
  author={Landgrebe, Jobst and Smith, Barry},
  journal={arXiv preprint arXiv:1906.05833},
  year={2019}
}

@article{emmert2024chatgpt,
  title={Is ChatGPT the way toward artificial general intelligence},
  author={Emmert-Streib, Frank},
  journal={Discover Artificial Intelligence},
  volume={4},
  number={1},
  pages={1--8},
  year={2024},
  publisher={Springer}
}

@article{pfister2025understanding,
  title={Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI},
  author={Pfister, Rolf and Jud, Hansueli},
  journal={arXiv preprint arXiv:2501.07458},
  year={2025}
}

@article{blumenthal2017development,
  title={The development of problems within the phlogiston theories, 1766--1791},
  author={Blumenthal, Geoffrey and Ladyman, James},
  journal={Foundations of Chemistry},
  volume={19},
  pages={241--280},
  year={2017},
  publisher={Springer}
}

@article{injadat2021machine,
  title={Machine learning towards intelligent systems: applications, challenges, and opportunities},
  author={Injadat, MohammadNoor and Moubayed, Abdallah and Nassif, Ali Bou and Shami, Abdallah},
  journal={Artificial Intelligence Review},
  volume={54},
  number={5},
  pages={3299--3348},
  year={2021},
  publisher={Springer}
}

@article{kumpulainen2022artificial,
  title={Artificial general intelligence vs. industry 4.0: Do they need each other?},
  author={Kumpulainen, Samu and Terziyan, Vagan},
  journal={Procedia Computer Science},
  volume={200},
  pages={140--150},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{thorisson2016artificial,
  title={Why artificial intelligence needs a task theory: And what it might look like},
  author={Th{\'o}risson, Kristinn R and Bieger, Jordi and Thorarensen, Thr{\"o}stur and Sigur{\dh}ard{\'o}ttir, J{\'o}na S and Steunebrink, Bas R},
  booktitle={Artificial General Intelligence: 9th International Conference, AGI 2016, New York, NY, USA, July 16-19, 2016, Proceedings 9},
  pages={118--128},
  year={2016},
  organization={Springer}
}

@article{van2021much,
  title={How much intelligence is there in artificial intelligence? A 2020 update},
  author={Van der Maas, Han LJ and Snoek, Lukas and Stevenson, Claire E},
  journal={Intelligence},
  volume={87},
  pages={101548},
  year={2021},
  publisher={Elsevier}
}

 @article{fjelland2020general,
  title={Why general artificial intelligence will not be realized},
  author={Fjelland, Ragnar},
  journal={Humanities and Social Sciences Communications},
  volume={7},
  number={1},
  pages={1--9},
  year={2020},
  publisher={Palgrave}
}

@article{morris2023levels,
  title={Levels of AGI: Operationalizing Progress on the Path to AGI},
  author={Morris, Meredith Ringel and Sohl-Dickstein, Jascha and Fiedel, Noah and Warkentin, Tris and Dafoe, Allan and Faust, Aleksandra and Farabet, Clement and Legg, Shane},
  journal={arXiv preprint arXiv:2311.02462},
  year={2023}
}

@inproceedings{mcduff2024cognitive,
  title={Cognitive Assessment of Language Models},
  author={McDuff, Daniel and Munday, David and Liu, Xin and Galatzer-Levy, Isaac},
  booktitle={ICML 2024 Workshop on LLMs and Cognition}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@article{chollet2019measure,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}

@article{ruder2017overview,
  title={An Overview of Multi-Task Learning in Deep Neural Networks},
  author={Ruder, S},
  journal={arXiv preprint arXiv:1706.05098},
  year={2017}
}

@article{henderson2017benchmark,
  title={Benchmark environments for multitask learning in continuous domains},
  author={Henderson, Peter and Chang, Wei-Di and Shkurti, Florian and Hansen, Johanna and Meger, David and Dudek, Gregory},
  journal={arXiv preprint arXiv:1708.04352},
  year={2017}
}

@article{burden2023inferring,
  title={Inferring Capabilities from Task Performance with Bayesian Triangulation},
  author={Burden, John and Voudouris, Konstantinos and Burnell, Ryan and Rutar, Danaja and Cheke, Lucy and Hern{\'a}ndez-Orallo, Jos{\'e}},
  journal={arXiv preprint arXiv:2309.11975},
  year={2023}
}

@article{dowe2014universal,
  title={How universal can an intelligence test be?},
  author={Dowe, David L and Hern{\'a}ndez-Orallo, Jos{\'e}},
  journal={Adaptive Behavior},
  volume={22},
  number={1},
  pages={51--69},
  year={2014},
  publisher={Sage Publications Sage UK: London, England}
}

@inproceedings{bender2021dangers,
  title={On the dangers of stochastic parrots: Can language models be too big?},
  author={Bender, Emily M and Gebru, Timnit and McMillan-Major, Angelina and Shmitchell, Shmargaret},
  booktitle={Proceedings of the 2021 ACM conference on fairness, accountability, and transparency},
  pages={610--623},
  year={2021}
}

@inproceedings{saba2023stochastic,
  title={Stochastic LLMs do not understand language: towards symbolic, explainable and ontologically based LLMs},
  author={Saba, Walid S},
  booktitle={International Conference on Conceptual Modeling},
  pages={3--19},
  year={2023},
  organization={Springer}
}

@inproceedings{valmeekam2022large,
  title={Large language models still can't plan (a benchmark for LLMs on planning and reasoning about change)},
  author={Valmeekam, Karthik and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  booktitle={NeurIPS 2022 Foundation Models for Decision Making Workshop},
  year={2022}
}






